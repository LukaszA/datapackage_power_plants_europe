{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Prepare the environment](#Prepare-the-environment)\n",
    "* [Definition of download sources](#Definition-of-download-sources)\n",
    "* [Define costum python functions](#Define-costum-python-functions)\n",
    "* [Download of data](#Download-of-data)\n",
    "* [Belgium](#Belgium)\n",
    "\t* [Import data](#Import-data)\n",
    "\t* [Translate and adjust columns](#Translate-and-adjust-columns)\n",
    "\t* [Generate information concerning Type and CHP](#Generate-information-concerning-Type-and-CHP)\n",
    "\t* [Translate and adjust Technology types](#Translate-and-adjust-Technology-types)\n",
    "\t* [Translate and adjust Fuel types](#Translate-and-adjust-Fuel-types)\n",
    "\t* [Generate information concerning Technology](#Generate-information-concerning-Technology)\n",
    "* [The Netherlands](#The-Netherlands)\n",
    "\t* [Import and merge data](#Import-and-merge-data)\n",
    "\t* [Translate and adjust columns](#Translate-and-adjust-columns)\n",
    "\t* [Translate and adjust Fuel types](#Translate-and-adjust-Fuel-types)\n",
    "\t* [Adjust Capacity](#Adjust-Capacity)\n",
    "* [Italy](#Italy)\n",
    "\t* [Import data](#Import-data)\n",
    "\t* [Translate and adjust columns](#Translate-and-adjust-columns)\n",
    "\t* [Translate and adjust Fuel types](#Translate-and-adjust-Fuel-types)\n",
    "* [France](#France)\n",
    "\t* [Import data](#Import-data)\n",
    "\t* [Translate and adjust Columns](#Translate-and-adjust-Columns)\n",
    "\t* [Translate and adjust Fuel types](#Translate-and-adjust-Fuel-types)\n",
    "\t* [Generate Technology types](#Generate-Technology-types)\n",
    "* [Finland](#Finland)\n",
    "\t* [Import data](#Import-data)\n",
    "\t* [Translate and adjust columns](#Translate-and-adjust-columns)\n",
    "\t* [Translate and adjust Fuel types](#Translate-and-adjust-Fuel-types)\n",
    "\t* [Generate Technology types](#Generate-Technology-types)\n",
    "\t* [Translate and adjust Types](#Translate-and-adjust-Types)\n",
    "* [Poland](#Poland)\n",
    "\t* [Import data](#Import-data)\n",
    "\t* [Translate and adjust Columns](#Translate-and-adjust-Columns)\n",
    "\t* [Translate and adjust Fuel types](#Translate-and-adjust-Fuel-types)\n",
    "\t* [Generate Technology types](#Generate-Technology-types)\n",
    "\t* [Merger of the multiple Lists](#Merger-of-the-multiple-Lists)\n",
    "* [Spain](#Spain)\n",
    "\t* [Import data](#Import-data)\n",
    "\t* [Translate and adjust Columns](#Translate-and-adjust-Columns)\n",
    "\t* [Translate and adjust Fuel types](#Translate-and-adjust-Fuel-types)\n",
    "\t* [Translate and adjust Technology types](#Translate-and-adjust-Technology-types)\n",
    "\t* [Generate and adjust Fuel types](#Generate-and-adjust-Fuel-types)\n",
    "* [United Kingdom](#United-Kingdom)\n",
    "\t* [Import data](#Import-data)\n",
    "\t* [Translate and adjust Columns](#Translate-and-adjust-Columns)\n",
    "\t* [Generate and adjust Technology types](#Generate-and-adjust-Technology-types)\n",
    "\t* [Translate and adjust Fuel types](#Translate-and-adjust-Fuel-types)\n",
    "* [Czech Republic](#Czech-Republic)\n",
    "\t* [Import data](#Import-data)\n",
    "\t* [Translate and adjust columns](#Translate-and-adjust-columns)\n",
    "\t* [Translate and adjust Technology types](#Translate-and-adjust-Technology-types)\n",
    "\t* [Merger of the multiple Lists](#Merger-of-the-multiple-Lists)\n",
    "* [Switzerland](#Switzerland)\n",
    "\t* [Import of hydropower data](#Import-of-hydropower-data)\n",
    "* [Create output-files](#Create-output-files)\n",
    "* [Documenting the data package (meta data)](#Documenting-the-data-package-%28meta-data%29)\n",
    "* [Write results to file](#Write-results-to-file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of every module and function needed to process the data and creation of the target folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import posixpath\n",
    "import urllib.parse\n",
    "import datetime  \n",
    "import re\n",
    "import os.path\n",
    "import yaml  # http://pyyaml.org/, pip install pyyaml, conda install pyyaml\n",
    "import json\n",
    "import datetime\n",
    "import subprocess\n",
    "from simpledbf import Dbf5 # required to import dbf file for CH\n",
    "import pyproj # required for transforming coordinates\n",
    "from bokeh.charts import Scatter, show\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "%matplotlib inline\n",
    "import logging\n",
    "logger = logging.getLogger('notebook')\n",
    "logger.setLevel('INFO')\n",
    "nb_root_logger = logging.getLogger()\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                              datefmt='%d %b %Y %H:%M:%S')\n",
    "nb_root_logger.handlers[0].setFormatter(formatter)\n",
    "\n",
    "#create download and output folder if they do not exist\n",
    "os.makedirs('data_downloaded', exist_ok=True)\n",
    "os.makedirs('data_processed', exist_ok=True)\n",
    "os.makedirs('data_final', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of download sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input of relevant meta data for every country and data source to facilitate the download loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = \"\"\"\n",
    "    BE: \n",
    "        Elia: \n",
    "            url_template: http://publications.elia.be/upload/ProductionParkOverview.xls?TS=20120416193815\n",
    "            filename: ProductionParkOverview\n",
    "            filetype: xls\n",
    "            sheetname: 'ProductionParkOverview'\n",
    "            skiprows: 1\n",
    "    NL: \n",
    "        Tennet_Q12015: \n",
    "            url_template: http://www.tennet.org/english/operational_management/export_data.aspx?exporttype=installedcapacity&format=csv&quarter=2015-1&submit=3\n",
    "            filename: export_Q12015\n",
    "            filetype: csv\n",
    "            sep: ','\n",
    "            skiprows: 0\n",
    "            decimal: '.'\n",
    "            encoding: 'utf-8'\n",
    "        Tennet_Q22015: \n",
    "            url_template: http://www.tennet.org/english/operational_management/export_data.aspx?exporttype=installedcapacity&format=csv&quarter=2015-2&submit=3\n",
    "            filename: export_Q22015\n",
    "            filetype: csv\n",
    "            sep: ','\n",
    "            skiprows: 0\n",
    "            decimal: '.'\n",
    "            encoding: 'utf-8'\n",
    "        Tennet_Q32015: \n",
    "            url_template: http://www.tennet.org/english/operational_management/export_data.aspx?exporttype=installedcapacity&format=csv&quarter=2015-3&submit=3\n",
    "            filename: export_Q32015\n",
    "            filetype: csv\n",
    "            sep: ','\n",
    "            skiprows: 0\n",
    "            decimal: '.'\n",
    "            encoding: 'utf-8'\n",
    "        Tennet_Q42015: \n",
    "            url_template: http://www.tennet.org/english/operational_management/export_data.aspx?exporttype=installedcapacity&format=csv&quarter=2015-4&submit=3\n",
    "            filename: export_Q42015\n",
    "            filetype: csv\n",
    "            sep: ','\n",
    "            skiprows: 0\n",
    "            decimal: '.'\n",
    "            encoding: 'utf-8'\n",
    "    IT:\n",
    "        Terna: \n",
    "            url_template: http://download.terna.it/terna/0000/0216/16.XLSX \n",
    "            filename: 16\n",
    "            filetype: xls\n",
    "            sheetname: 'UPR PmaxOver 100MW'\n",
    "            skiprows: 0\n",
    "\n",
    "# http://www.terna.it/it-it/sistemaelettrico/transparencyreport/generation/installedgenerationcapacity.aspx\n",
    "    \n",
    "    FR: \n",
    "        RTE: \n",
    "            url_template: http://clients.rte-france.com/servlets/CodesEICServlet\n",
    "            filename: Centrales_production_reference\n",
    "            filetype: zip\n",
    "            sep: '\\t'\n",
    "            skiprows: 2\n",
    "            decimal: ','\n",
    "            encoding: 'cp1252'\n",
    "            \n",
    "    ES: \n",
    "        SEDE: \n",
    "            url_template: http://www6.mityc.es/aplicaciones/electra/ElectraExp.csv.zip\n",
    "            filename: ElectraExp\n",
    "            filetype: zip\n",
    "            sep: ';'\n",
    "            skiprows: 0\n",
    "            decimal: ','\n",
    "            encoding: 'utf-8'\n",
    "\n",
    "# https://sedeaplicaciones.minetur.gob.es/electra/BuscarDatos.aspx\n",
    "\n",
    "    FI: \n",
    "        EnergyAuthority: \n",
    "            url_template: http://www.energiavirasto.fi/documents/10191/0/Energiaviraston+Voimalaitosrekisteri+040316.xlsx\n",
    "            filename: Energiaviraston+Voimalaitosrekisteri+040316\n",
    "            filetype: xlsx\n",
    "            sheetname: 'English'\n",
    "            skiprows: 1\n",
    "            \n",
    "#    DK1: \n",
    "#        EnerginetDK: \n",
    "#            url_template: https://www.energinet.dk/SiteCollectionDocuments/Engelske%20dokumenter/El/Energinet%20dk%27s%20assumptions%20for%20analysis%202014-2035,%20September%202014.xlsm\n",
    "#            filename: Energinet dk's assumptions for analysis 2014-2035, September 2014\n",
    "#            filetype: xlsm\n",
    "#            sheetname: 'Power plants, West'\n",
    "#            skiprows: 6\n",
    "    \n",
    "#    DK2: \n",
    "#        EnerginetDK: \n",
    "#            url_template: https://www.energinet.dk/SiteCollectionDocuments/Engelske%20dokumenter/El/Energinet%20dk%27s%20assumptions%20for%20analysis%202014-2035,%20September%202014.xlsm\n",
    "#            filename: Energinet dk's assumptions for analysis 2014-2035, September 2014\n",
    "#            filetype: xlsm\n",
    "#            sheetname: 'Power plants, East'\n",
    "#            skiprows: 6\n",
    "  \n",
    "    PL: \n",
    "        GPI: \n",
    "            url_template: http://gpi.tge.pl/en/wykaz-jednostek?p_p_id=powerunits_WAR_powerunitsportlet&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_cacheability=cacheLevelPage&p_p_col_id=column-1&p_p_col_count=1\n",
    "            filename: units_list\n",
    "            filetype: csv            \n",
    "            sep: ';'\n",
    "            skiprows: 0\n",
    "            decimal: '.'\n",
    "            encoding: 'utf-8'\n",
    "\n",
    "    UK: \n",
    "        GOV: \n",
    "            url_template: https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/446457/dukes5_10.xls\n",
    "            filename: dukes5_10\n",
    "            filetype: xls\n",
    "            sheetname: 'Database'\n",
    "            skiprows: 3\n",
    "            \n",
    "    CZ:\n",
    "        CEPS:\n",
    "            url_template: http://www.ceps.cz/_layouts/15/Ceps/_Pages/GraphData.aspx?mode=xlsx&from=1/1/2010%2012:00:00%20AM&to=12/31/2015%2011:59:59%20PM&hasinterval=False&sol=9&lang=ENG&ver=YF&\n",
    "            filename: Data\n",
    "            filetype: xlsx\n",
    "            sheetname: 'NewWorksheet'\n",
    "            skiprows: 2\n",
    "  \n",
    "    CH:\n",
    "        BFE_HydroData:\n",
    "            url_template: http://www.bfe.admin.ch/php/modules/publikationen/stream.php?extlang=de&name=de_416798061.zip&endung=Statistik%20der%20Wasserkraftanlagen%20der%20Schweiz\n",
    "            filename: 'Statistik der Wasserkraftanlagen der Schweiz 1.1.2016'\n",
    "            filetype: zip\n",
    "            sep: ';'\n",
    "            skiprows: 0\n",
    "            decimal: '.'\n",
    "            encoding: 'cp1252'\n",
    "        BFE_HydroGeo:\n",
    "            url_template: http://www.bfe.admin.ch/php/modules/publikationen/stream.php?extlang=de&name=de_123526626.zip&endung=Statistik%20der%20Wasserkraftanlagen%20(WASTA)%20-%20Geodaten%20im%20SHAPE-Format\n",
    "            filename: HydropowerPlant\n",
    "            filetype: zip\n",
    "            encoding: 'cp1252'\n",
    "            \n",
    "            \n",
    "  \"\"\"\n",
    "conf = yaml.load(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define costum python functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the download process and adjustment of the file name according to the acutal date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def downloadandcache(url,filename,filetype):\n",
    "    \"\"\"This function downloads a file into a folder called \n",
    "    data-downloaded and returns the local filepath.\"\"\"\n",
    "    path = urllib.parse.urlsplit(url).path\n",
    "#   filename = posixpath.basename(path)\n",
    "    filename = str(filename)\n",
    "    filetype = filetype\n",
    "    now = datetime.datetime.now()\n",
    "    datestring = \"\"\n",
    "    datestring = str(now.year)+\"-\"+str(now.month)+\"-\"+str(now.day)\n",
    "    filepath = \"data_downloaded/\"+datestring+\"-\"+filename+\".\"+filetype\n",
    "    filepath_original_data = \"data_original/\"+filename+\".\"+filetype\n",
    "    \n",
    "    #check if file exists, otherwise download it\n",
    "    if os.path.exists(filepath) == False:\n",
    "        print(\"Downloading file\", filename+\".\"+filetype)\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "        urllib.request.urlretrieve(url, filepath_original_data)\n",
    "    else:\n",
    "        print(\"Using local file from\", filepath)\n",
    "    filepath = './'+filepath\n",
    "    return filepath\n",
    "\n",
    "def importdata(country,tso):\n",
    "    now = datetime.datetime.now()\n",
    "    datestring = \"\"\n",
    "    datestring = str(now.year)+\"-\"+str(now.month)+\"-\"+str(now.day)\n",
    "    data_import=pd.DataFrame()\n",
    "    param = conf[country][tso]\n",
    "    filepath = \"data_downloaded/\"+datestring+\"-\"+str(param['filename'])+\".\"+param['filetype']\n",
    "    if param['filetype'] == 'csv':\n",
    "        data_import = pd.read_csv(filepath,\n",
    "                              sep=param['sep'],\n",
    "                              skiprows=param['skiprows'],\n",
    "                              decimal=param['decimal'],   \n",
    "                              encoding=param['encoding'])\n",
    "    elif param['filetype'] =='dbf':\n",
    "        dbf = Dbf5(filepath, codec=param['encoding'])\n",
    "        data_import = dbf.to_dataframe()\n",
    "    else: \n",
    "        data_import = pd.read_excel(filepath,\n",
    "                                    sheetname=param['sheetname'],\n",
    "                                    skiprows=param['skiprows'])\n",
    "    \n",
    "    data_import['Country'] = str(country)\n",
    "    data_import['Source'] = str(tso)\n",
    "    \n",
    "    return data_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of the download loop. Consideration of two exceptions due to file types (ZIP-file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for country, tso in conf.items():\n",
    "    for tso, param in tso.items():\n",
    "        print(param['url_template'])\n",
    "#        make_url(param['url_template'],param['filetype'])\n",
    "        downloadandcache(param['url_template'],param['filename'],param['filetype'])\n",
    "\n",
    "# Special case FR (RTE): ZIP-file with corrupted xls-file is provided, which needs to be renamed to csv \n",
    "        if country=='FR':\n",
    "            now = datetime.datetime.now()\n",
    "            datestring = str(now.year)+\"-\"+str(now.month)+\"-\"+str(now.day)\n",
    "            filepath = \"data_downloaded/\"+datestring+\"-\"+param['filename']\n",
    "\n",
    "            with zipfile.ZipFile(filepath+\".zip\",\"r\") as O:\n",
    "                O.extractall(\"data_downloaded/\")\n",
    "            if os.path.exists(filepath+\".csv\") == False:\n",
    "                os.rename(\"data_downloaded/\"+param['filename']+\".xls\",filepath+\".csv\")\n",
    "            # change filetype from zip to csv\n",
    "            conf[country][tso]['filetype'] = \"csv\"\n",
    "\n",
    "# Special case ES (SEDE): ZIP-file with csv file \n",
    "        if country=='ES':\n",
    "            now = datetime.datetime.now()\n",
    "            datestring = str(now.year)+\"-\"+str(now.month)+\"-\"+str(now.day)\n",
    "            filepath = \"data_downloaded/\"+datestring+\"-\"+param['filename']\n",
    "\n",
    "            with zipfile.ZipFile(filepath+\".zip\",\"r\") as O:\n",
    "                O.extractall(\"data_downloaded/\")\n",
    "            if os.path.exists(filepath+\".csv\") == False:\n",
    "                os.rename(\"data_downloaded/\"+param['filename']+\".csv\",filepath+\".csv\")\n",
    "            # change filetype from zip to csv\n",
    "            conf[country][tso]['filetype'] = \"csv\"\n",
    "#            print(conf)\n",
    "\n",
    "# Special case CH (BFE): ZIP-file with csv file \n",
    "        if country=='CH' and tso=='BFE_HydroData':\n",
    "            now = datetime.datetime.now()\n",
    "            datestring = str(now.year)+\"-\"+str(now.month)+\"-\"+str(now.day)\n",
    "            filepath = \"data_downloaded/\"+datestring+\"-\"+param['filename']\n",
    "\n",
    "            with zipfile.ZipFile(filepath+\".zip\",\"r\") as O:\n",
    "                O.extractall(\"data_downloaded/\")\n",
    "            if os.path.exists(filepath+\".csv\") == False:\n",
    "                os.rename(\"data_downloaded/\"+param['filename']+\".csv\",filepath+\".csv\")\n",
    "            # change filetype from zip to csv\n",
    "            conf[country][tso]['filetype'] = \"csv\"\n",
    "    #        print(conf)\n",
    "\n",
    "        if country=='CH' and tso=='BFE_HydroGeo':\n",
    "            now = datetime.datetime.now()\n",
    "            datestring = str(now.year)+\"-\"+str(now.month)+\"-\"+str(now.day)\n",
    "            filepath = \"data_downloaded/\"+datestring+\"-\"+param['filename']\n",
    "\n",
    "            with zipfile.ZipFile(filepath+\".zip\",\"r\") as O:\n",
    "                O.extractall(\"data_downloaded/\")\n",
    "            if os.path.exists(filepath+\".dbf\") == False:\n",
    "                os.rename(\"data_downloaded/\"+param['filename']+\".dbf\",filepath+\".dbf\")\n",
    "            # change filetype from zip to csv\n",
    "            conf[country][tso]['filetype'] = \"dbf\"\n",
    "        \n",
    "#print(conf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Belgium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if input works\n",
    "data_BE = importdata('BE','Elia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall adjustment of all columns within the dataframe. \n",
    "Translation, addition, deletion, sorting of columns as well as adjustment of the column entries' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop columns not needed anymore\n",
    "colsToDrop = ['Unnamed: 0', \n",
    "              'Unnamed: 2', \n",
    "              'Unnamed: 4', \n",
    "              'Unnamed: 6', \n",
    "              'Unnamed: 7', \n",
    "              'Fuel for publication',\n",
    "              'Unnamed: 11']\n",
    "data_BE = data_BE.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Translate columns\n",
    "dict_columns_BE = {'ARP':'Company',\n",
    "                   'Generation plant':'Name',\n",
    "                   'Plant Type':'Technology',\n",
    "                   'Technical Nominal Power (MW)':'Capacity',\n",
    "                   'Remarks':'Comment',\n",
    "                   'Fuel':'Fuel',\n",
    "                   'Country':'Country',\n",
    "                   'Source':'Source'}\n",
    "data_BE.rename(columns=dict_columns_BE, inplace=True)\n",
    "\n",
    "# Check if all columns have been translated\n",
    "for columnnames in data_BE.columns:\n",
    "    #print(columnnames)\n",
    "    if not columnnames in dict_columns_BE.values():\n",
    "        logger.error(\"Untranslated column: \"+ columnnames)\n",
    "\n",
    "# Add needed columns without data\n",
    "data_BE['Street',\n",
    "        'Postcode',\n",
    "        'City',\n",
    "        'CHP',\n",
    "        'Type',\n",
    "        'Commissioned'] = 'NaN'\n",
    "\n",
    "# Sort columns\n",
    "columns_sorted_BE = ['Company',\n",
    "                     'Name',\n",
    "                     'Street',\n",
    "                     'Postcode',\n",
    "                     'City',\n",
    "                     'Country',\n",
    "                     'Capacity',\n",
    "                     'Fuel',\n",
    "                     'Technology',\n",
    "                     'Type',\n",
    "                     'CHP',\n",
    "                     'Commissioned',\n",
    "                     'Comment',\n",
    "                     'Source',\n",
    "                     'EIC-Code',\n",
    "                     'Availability',\n",
    "                     'Lat',\n",
    "                     'Lon']\n",
    "data_BE = data_BE.reindex(columns=columns_sorted_BE)\n",
    "\n",
    "# Drop rows without capacity entries, so that row with \"Unit connected to Distribution Grid\" is dropped\n",
    "data_BE = data_BE.dropna(subset=['Capacity'])\n",
    "\n",
    "#Adjust types of entries in all columns\n",
    "data_BE.Company = data_BE.Company.astype(str)\n",
    "data_BE.Name = data_BE.Name.astype(str)\n",
    "data_BE.Street = data_BE.Street.astype(str)\n",
    "data_BE.Postcode = data_BE.Postcode.astype(str)\n",
    "data_BE.City = data_BE.City.astype(str)\n",
    "data_BE.Country = data_BE.Country.astype(str)\n",
    "data_BE.Capacity = data_BE.Capacity.astype(float)\n",
    "data_BE.Fuel = data_BE.Fuel.astype(str)\n",
    "data_BE.Technology = data_BE.Technology.astype(str)\n",
    "data_BE.Type = data_BE.Type.astype(str)\n",
    "data_BE.CHP = data_BE.CHP.astype(str)\n",
    "data_BE.Commissioned = data_BE.Commissioned.astype(str)\n",
    "data_BE.Comment = data_BE.Comment.astype(str)\n",
    "data_BE.Source = data_BE.Source.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate information concerning Type and CHP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of entries for the columns \"Type\" and \"CHP\" according to information given in the columns \"Technology\" and \"Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate entries in column \"type\" according to technology \"WKK\"\n",
    "data_BE['Type'][data_BE['Technology'] == 'WKK'] = 'CHP'\n",
    "\n",
    "# Generate entries in column \"CHP\" according to column \"type\"\n",
    "data_BE['CHP'][data_BE['Type'] == 'CHP'] = 'Yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Technology types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: workaround for 'WKK' - Extract technology from name\n",
    "\n",
    "Overall translation of all technology types mentioned in the column \"Technology\" and subsequent translation check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translate technologies\n",
    "dict_technology_BE = {'BG':'GT',\n",
    "                      'CL': 'UNKNOWN',\n",
    "                      'WKK': 'UNKNOWN',\n",
    "                      'CCGT': 'CC',\n",
    "                      'D':'UNKNOWN',\n",
    "                      'HU':'hydro_plant',\n",
    "                      'IS':'UNKNOWN',\n",
    "                      'NU':'ST',\n",
    "                      'TJ':'UNKNOWN',\n",
    "                      'WT':'wind_turbine',\n",
    "                     ' ':'UNKNOWN'}\n",
    "data_BE[\"Technology\"].replace(dict_technology_BE, inplace=True)\n",
    "data_BE[\"Technology\"].unique()\n",
    "\n",
    "# Check if all technologies have been translated\n",
    "for technology in data_BE[\"Technology\"].unique():\n",
    "    if (not technology in dict_technology_BE.values()) & (str(technology) != \"nan\"):\n",
    "        logger.error(\"Untranslated technology: \" + str(technology))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Fuel types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all fuel types mentioned in the column \"Fuel\" and subsequent translation check. Deletion of rows containing \"wind\" as fuel type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translate fuel types\n",
    "dict_fuels_BE = {'BIO':'biomass',\n",
    "                 'BF':'gas',\n",
    "                 'CL':'lignite',\n",
    "                 'CP':'coal',\n",
    "                 'CG':'gas',\n",
    "                 'GO':'multiple_non_renewable',\n",
    "                 'LF':'oil',\n",
    "                 'LV':'oil',\n",
    "                 'CP/BF':'multiple_non_renewable',\n",
    "                 'CP/CG':'multiple_non_renewable',\n",
    "                 'FA/BF':'multiple_non_renewable',\n",
    "                 'NG/BF':'gas',\n",
    "                 'NG':'gas',\n",
    "                 'NU':'uranium',\n",
    "                 'WR':'waste',\n",
    "                 'WA':'hydro',\n",
    "                 'WI':'wind',\n",
    "                 'WP':'biomass'}\n",
    "data_BE[\"Fuel\"].replace(dict_fuels_BE, inplace=True)\n",
    "data_BE[\"Fuel\"].unique()\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for fuel in data_BE[\"Fuel\"].unique():\n",
    "    if (not fuel in dict_fuels_BE.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Untranslated fuel type: \" + str(fuel))\n",
    "\n",
    "# Delete unwanted fuels (wind) in column \"fuel\"\n",
    "data_BE = data_BE[data_BE.Fuel != 'wind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate information concerning Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of entries for the column \"Technology\" according to information given in the columns \"Fuel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate entries in column \"technology\" according to fuel \"hydro\"\n",
    "data_BE['Technology'][data_BE['Fuel'] == 'hydro'] = 'hydro_plant'\n",
    "\n",
    "data_BE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if input works\n",
    "data_NL_Q12015 = importdata('NL','Tennet_Q12015')\n",
    "data_NL_Q22015 = importdata('NL','Tennet_Q22015')\n",
    "data_NL_Q32015 = importdata('NL','Tennet_Q32015')\n",
    "data_NL_Q42015 = importdata('NL','Tennet_Q42015')\n",
    "\n",
    "# Append the lists to one list\n",
    "data_NL_Q1_Q22015 = data_NL_Q12015.append(data_NL_Q22015)\n",
    "data_NL_Q1_Q32015 = data_NL_Q1_Q22015.append(data_NL_Q32015)\n",
    "data_NL_Q1_Q42015 = data_NL_Q1_Q32015.append(data_NL_Q42015)\n",
    "\n",
    "# Rename the appended list\n",
    "data_NL = data_NL_Q1_Q42015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall adjustment of all columns within the dataframe. Translation, addition, deletion, merger, sorting of columns as well as adjustment of the column entries' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add needed columns without data\n",
    "data_NL['Technology'] = 'UNKNOWN'\n",
    "data_NL['Type'] = 'NaN'\n",
    "data_NL['Comment'] = 'NaN'\n",
    "data_NL['CHP'] = 'NaN'\n",
    "data_NL['Type'] = 'NaN'\n",
    "data_NL['Street'] = 'NaN'\n",
    "data_NL['Commissioned'] = 'NaN'\n",
    "\n",
    "# Merge columns \"street\" and \"Number\" to one column called \"Street\"\n",
    "data_NL['Street'] = data_NL[['street','Number']].apply(lambda x : '{} {}'.format(x[0],x[1]), axis=1)\n",
    "\n",
    "# Drop columns not needed anymore\n",
    "colsToDrop = ['Location', 'Date', 'street', 'Number']\n",
    "data_NL = data_NL.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Rename columns\n",
    "dict_columns_NL = {'Connected body':'Company',\n",
    "                   'Entity':'Name',\n",
    "                   'zipcode':'Postcode',\n",
    "                   'place-name':'City',\n",
    "                   'Country':'Country',\n",
    "                   'Fuel':'Fuel',\n",
    "                   'Capacity':'Capacity',\n",
    "                   'Technology':'Technology',\n",
    "                   'Type':'Type',\n",
    "                   'Comment':'Comment',\n",
    "                   'CHP':'CHP',\n",
    "                   'Commissioned':'Commissioned',\n",
    "                   'Street':'Street',\n",
    "                   'Source':'Source'}\n",
    "data_NL.rename(columns=dict_columns_NL, inplace=True)\n",
    "\n",
    "# Check if all columns have been renamed\n",
    "for columnnames in data_NL.columns:\n",
    "    #print(columnnames)\n",
    "    if not columnnames in dict_columns_NL.values():\n",
    "        logger.error(\"Not renamed column: \"+ columnnames)\n",
    "\n",
    "#Adjust types of entries in all columns\n",
    "data_NL.Company = data_NL.Company.astype(str)\n",
    "data_NL.Name = data_NL.Name.astype(str)\n",
    "data_NL.Street = data_NL.Street.astype(str)\n",
    "data_NL.Postcode = data_NL.Postcode.astype(str)\n",
    "data_NL.City = data_NL.City.astype(str)\n",
    "data_NL.Country = data_NL.Country.astype(str)\n",
    "data_NL.Capacity = data_NL.Capacity.astype(float)\n",
    "data_NL.Fuel = data_NL.Fuel.astype(str)\n",
    "data_NL.Technology = data_NL.Technology.astype(str)\n",
    "data_NL.Type = data_NL.Type.astype(str)\n",
    "data_NL.CHP = data_NL.CHP.astype(str)\n",
    "data_NL.Commissioned = data_NL.Commissioned.astype(str)\n",
    "data_NL.Comment = data_NL.Comment.astype(str)\n",
    "data_NL.Source = data_NL.Source.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Fuel types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all fuel types mentioned in the column \"Fuel\" and subsequent translation check. Generation of entries for the column \"Technology\" according to information given in the column \"Fuel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename fuel types according to \n",
    "# http://www.tennet.org/english/operational_management/system_data_preparation/Reported_production_capacity/Installed_capacity.aspx\n",
    "dict_fuels_NL = {'E01':'solar',\n",
    "                 'E02':'wind',\n",
    "                 'E03':'hydro',\n",
    "                 'E04':'biomass',\n",
    "                 'E05':'coal',\n",
    "                 'E06':'gas',\n",
    "                 'E07':'oil',\n",
    "                 'E08':'uranium',\n",
    "                 'E09':'UNKNOWN'}\n",
    "data_NL[\"Fuel\"].replace(dict_fuels_NL, inplace=True)\n",
    "data_NL[\"Fuel\"].unique()\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for fuel in data_NL[\"Fuel\"].unique():\n",
    "    if (not fuel in dict_fuels_NL.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Not renamed fuel type: \" + str(fuel))\n",
    "\n",
    "data_NL['Technology'][data_NL['Fuel'] == 'uranium'] = 'ST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust Capacity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjustment of the capacity entry for the row relating to the power plant named \"Rijnmond II\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data for power plant 'Rijnmond II' are daily total capacity\n",
    "data_NL['Capacity_new'] = (data_NL['Capacity']/24).where(data_NL.Name == 'Rijnmond II')\n",
    "data_NL['Capacity'][data_NL.Name == 'Rijnmond II'] = data_NL['Capacity_new']\n",
    "data_NL = data_NL.drop(['Capacity_new'], axis=1)\n",
    "\n",
    "# Filter rows by considering \"name\" and maximum \"capacity\n",
    "#data_NL = data_NL[data_NL['Name'] != data_NL['Name'].shift(-1)]\n",
    "data_NL = data_NL.sort_values('Capacity', ascending=False).groupby('Name', as_index=False).first()\n",
    "\n",
    "# Sort order of columns\n",
    "columns_sorted_NL = ['Company',\n",
    "                     'Name',\n",
    "                     'Street',\n",
    "                     'Postcode',\n",
    "                     'City',\n",
    "                     'Country',\n",
    "                     'Capacity',\n",
    "                     'Fuel',\n",
    "                     'Technology',\n",
    "                     'Type',\n",
    "                     'CHP',\n",
    "                     'Commissioned',\n",
    "                     'Comment',\n",
    "                     'Source',\n",
    "                     'EIC-Code',\n",
    "                     'Availability',\n",
    "                     'Lat',\n",
    "                     'Lon']\n",
    "data_NL = data_NL.reindex(columns=columns_sorted_NL)\n",
    "\n",
    "data_NL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if input works\n",
    "data_IT = importdata('IT','Terna')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall adjustment of all columns within the dataframe. Translation, addition, deletion, sorting of columns as well as adjustment of the column entries' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop columns not needed anymore\n",
    "colsToDrop = ['CENSIMP',\n",
    "              'Codice di Rintracciabilità', \n",
    "              'Location', \n",
    "              'Voltage connection levels [kV]', \n",
    "              'Zona', \n",
    "              'Regione','Provincia']\n",
    "data_IT = data_IT.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Translate columns\n",
    "dict_columns_IT = {'Descrizione Impianto':'Name',\n",
    "                   'TIPOLOGIA':'Fuel',\n",
    "                   'Comune':'City',\n",
    "                   'PMAX [MW]':'Capacity',\n",
    "                   'Country':'Country',\n",
    "                   'Source':'Source'}\n",
    "data_IT.rename(columns=dict_columns_IT, inplace=True)\n",
    "\n",
    "# Check if all columns have been translated\n",
    "for columnnames in data_IT.columns:\n",
    "    #print(columnnames)\n",
    "    if not columnnames in dict_columns_IT.values():\n",
    "        logger.error(\"Untranslated column: \"+ columnnames)\n",
    "        \n",
    "# Add columns with empty data\n",
    "data_IT['Company', 'Street', 'Postcode', 'CHP','Type','Comment','Commissioned'] = 'NaN'\n",
    "data_IT['Technology']='UNKNOWN'\n",
    "\n",
    "# Sort columns\n",
    "columns_sorted_IT = ['Company',\n",
    "                     'Name',\n",
    "                     'Street',\n",
    "                     'Postcode',\n",
    "                     'City',\n",
    "                     'Country',\n",
    "                     'Capacity',\n",
    "                     'Fuel',\n",
    "                     'Technology',\n",
    "                     'Type',\n",
    "                     'CHP',\n",
    "                     'Commissioned',\n",
    "                     'Comment',\n",
    "                     'Source',\n",
    "                     'EIC-Code',\n",
    "                     'Availability',\n",
    "                     'Lat',\n",
    "                     'Lon']\n",
    "data_IT = data_IT.reindex(columns=columns_sorted_IT)\n",
    "\n",
    "#Adjust types of entries in all columns\n",
    "data_IT.Company = data_IT.Company.astype(str)\n",
    "data_IT.Name = data_IT.Name.astype(str)\n",
    "data_IT.Street = data_IT.Street.astype(str)\n",
    "data_IT.Postcode = data_IT.Postcode.astype(str)\n",
    "data_IT.City = data_IT.City.astype(str)\n",
    "data_IT.Country = data_IT.Country.astype(str)\n",
    "data_IT.Capacity = data_IT.Capacity.astype(float)\n",
    "data_IT.Fuel = data_IT.Fuel.astype(str)\n",
    "data_IT.Technology = data_IT.Technology.astype(str)\n",
    "data_IT.Type = data_IT.Type.astype(str)\n",
    "data_IT.CHP = data_IT.CHP.astype(str)\n",
    "data_IT.Commissioned = data_IT.Commissioned.astype(str)\n",
    "data_IT.Comment = data_IT.Comment.astype(str)\n",
    "data_IT.Source = data_IT.Source.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Fuel types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all fuel types mentioned in the column \"Fuel\" and subsequent translation check. Deletion of rows containing \"wind\" and \"geothermal_power\"as fuel type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translate fuel types\n",
    "dict_fuels_IT = {'GEOTERMICO':'geothermal_power',\n",
    "                 'TERMOELETTRICO': 'conventional',\n",
    "                 'IDROELETTRICO':'hydro',\n",
    "                 'EOLICO':'wind'}\n",
    "data_IT[\"Fuel\"].replace(dict_fuels_IT, inplace=True)\n",
    "data_IT[\"Fuel\"].unique()\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for fuel in data_IT[\"Fuel\"].unique():\n",
    "    if (not fuel in dict_fuels_IT.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Untranslated fuel type: \" + str(fuel)) \n",
    "\n",
    "# Generate technology entries according to fuels\n",
    "data_IT['Technology'][data_IT['Fuel'] == 'hydro'] = 'hydro_plant'\n",
    "\n",
    "# Delete unwanted fuels (wind & geothermal power) in column \"fuel\"\n",
    "data_IT = data_IT[data_IT.Fuel != 'wind']\n",
    "data_IT = data_IT[data_IT.Fuel != 'geothermal_power']\n",
    "\n",
    "data_IT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if input works\n",
    "data_FR = importdata('FR','RTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall adjustment of all columns within the dataframe. Translation, addition, deletion, sorting of columns as well as adjustment of the column entries' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop columns not needed anymore\n",
    "colsToDrop = ['Niveau de tension de connexion (KVT)', \n",
    "              'Date de suppression', \n",
    "              'Localisation']\n",
    "data_FR = data_FR.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Translate columns\n",
    "dict_columns_FR = {'Type':'Fuel',\n",
    "                   'Nom de la centrale de production':'Name',\n",
    "                   'Capacité de production Installée (MW)':'Capacity',\n",
    "                   'Date de création':'Commissioned',\n",
    "                   'Country':'Country',\n",
    "                   'Source':'Source'}\n",
    "data_FR.rename(columns=dict_columns_FR, inplace=True)\n",
    "\n",
    "# Check if all columns have been translated\n",
    "for columnnames in data_FR.columns:\n",
    "    #print(columnnames)\n",
    "    if not columnnames in dict_columns_FR.values():\n",
    "        logger.error(\"Untranslated column: \"+ columnnames)\n",
    "\n",
    "# Add columns with empty data\n",
    "data_FR['Company', 'Street', 'Postcode', 'City','Technology','CHP', 'Type', 'Comment'] = 'NaN'\n",
    "\n",
    "# Sort columns\n",
    "columns_sorted_FR = ['Company',\n",
    "                     'Name',\n",
    "                     'Street',\n",
    "                     'Postcode',\n",
    "                     'City',\n",
    "                     'Country',\n",
    "                     'Capacity',\n",
    "                     'Fuel',\n",
    "                     'Technology',\n",
    "                     'Type',\n",
    "                     'CHP',\n",
    "                     'Commissioned',\n",
    "                     'Comment',\n",
    "                     'Source',\n",
    "                     'EIC-Code',\n",
    "                     'Availability',\n",
    "                     'Lat',\n",
    "                     'Lon']\n",
    "data_FR = data_FR.reindex(columns=columns_sorted_FR)\n",
    "\n",
    "# Delete unwanted row by referring to column \"Name\"\n",
    "data_FR = data_FR.dropna(subset=['Name'])\n",
    "\n",
    "# Delete place holder datetime\n",
    "dict_date_FR = {'01/01/2000':'NaN'}\n",
    "data_FR[\"Commissioned\"].replace(dict_date_FR, inplace=True)\n",
    "data_FR[\"Commissioned\"].unique()\n",
    "\n",
    "# Define commissioning year\n",
    "#data_FR['Commissioned'][data_FR['Commissioned'] == '01/01/2000'] = np.nan\n",
    "data_FR['Commissioned'] = pd.to_datetime(data_FR['Commissioned'], format='%d/%m/%Y')\n",
    "data_FR['Commissioned'] = pd.DatetimeIndex(data_FR['Commissioned']).year\n",
    "\n",
    "#Adjust types of entries in all columns\n",
    "data_FR.Capacity = data_FR.Capacity.astype(float)\n",
    "#data_FR.Commissioned = data_FR.Commissioned.astype(int)\n",
    "\n",
    "data_FR.head()\n",
    "#print(data_FR.Commissioned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Fuel types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all fuel types mentioned in the column \"Fuel\" and subsequent translation check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translate fuel types\n",
    "dict_fuels_FR = {'Autre':'UNKNOWN',\n",
    "                 'Charbon':'coal',\n",
    "                 'Fioul': 'oil',\n",
    "                 'Gaz':'gas',\n",
    "                 'Hydraulique STEP':'pumped_storage',\n",
    "                 '''Hydraulique fil de l'eau / éclusée''':'run_of_river',\n",
    "                 'Hydraulique lacs':'reservoir',\n",
    "                 'Marin':'hydro_tidal',\n",
    "                 'Nucléaire':'uranium'}\n",
    "data_FR[\"Fuel\"].replace(dict_fuels_FR, inplace=True)\n",
    "data_FR[\"Fuel\"].unique()\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for fuel in data_FR[\"Fuel\"].unique():\n",
    "    if (not fuel in dict_fuels_FR.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Untranslated fuel type: \" + str(fuel)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Technology types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of entries for the column \"Technology\" according to information given in the column \"Fuel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate technology entries according to fuels\n",
    "data_FR['Technology'][data_FR['Fuel'] == 'pumped_storage'] = 'PSP'\n",
    "data_FR['Technology'][data_FR['Fuel'] == 'run_of_river'] = 'ROR'\n",
    "data_FR['Technology'][data_FR['Fuel'] == 'reservoir'] = 'RES'\n",
    "data_FR['Technology'][data_FR['Fuel'] == 'uranium'] = 'ST'\n",
    "data_FR['Technology'][data_FR['Fuel'] == 'hydro_tidal'] = 'hydro_plant'\n",
    "data_FR['Technology'][data_FR['Fuel'] == 'gas'] = 'UNKNOWN'\n",
    "data_FR['Technology'][data_FR['Fuel'] == 'oil'] = 'UNKNOWN'\n",
    "data_FR['Technology'][data_FR['Fuel'] == 'coal'] = 'UNKNOWN'\n",
    "data_FR['Technology'][data_FR['Fuel'] == 'UNKNOWN'] = 'UNKNOWN'\n",
    "\n",
    "dict_technologies_FR = {' ':'UNKNOWN'}\n",
    "data_FR[\"Technology\"].replace(dict_technologies_FR, inplace=True)\n",
    "data_FR[\"Technology\"].unique()\n",
    "\n",
    "data_FR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if input works\n",
    "data_FI = importdata('FI','EnergyAuthority')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall adjustment of all columns within the dataframe. Translation, addition, deletion, sorting of columns as well as adjustment of the column entries' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add columns with empty data\n",
    "data_FI['CHP'] = 'NaN'\n",
    "data_FI['Comment'] = 'NaN'\n",
    "data_FI['Technology'] = 'UNKNOWN'\n",
    "data_FI['Commissioned'] = 'NaN'\n",
    "\n",
    "# Generate entries in column \"CHP\"\n",
    "data_FI['CHP'] = 'No'\n",
    "data_FI['CHP'][data_FI['Combined Heat and Power Production, Industry,Maximum, Total, MW'] > 0] = 'Yes'\n",
    "data_FI['CHP'][data_FI['Combined Heat and Power Production, District Heating, Total, MW'] > 0] = 'Yes'\n",
    "\n",
    "# Drop columns not needed anymore\n",
    "colsToDrop = ['Business ID', \n",
    "              'Location', \n",
    "              'Separate power production, Maximum, Hour, MW', \n",
    "              'Separate power production, Decomissioned, Hour, MW',\n",
    "              'Combined Heat and Power Production, Industry,Maximum, Total, MW',\n",
    "              'Combined Heat and Power Production, Industry,Hour, Total, MW', \n",
    "              'Combined Heat and Power Production, Industry, Decomissioned, Total, MW',\n",
    "              'Combined Heat and Power Production, District Heating, Total, MW',\n",
    "              'Combined Heat and Power Production, District Heating, Hour, MW', \n",
    "              'Combined Heat and Power Production, District Heating, Decomissioned, Total, MW',\n",
    "              'Separate power production, Maximum, Total, MW',\n",
    "              'Hour, total, MW',\n",
    "              'Decomissioned, Total, MW',\n",
    "              'Standby fuel ',\n",
    "              'Standby fuel']\n",
    "data_FI = data_FI.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Rename columns\n",
    "dict_columns_FI = {'Name':'Name',\n",
    "                   'Company':'Company',\n",
    "                   'Type':'Type',\n",
    "                   'CHP':'CHP',\n",
    "                   'Comment':'Comment',\n",
    "                   'Technology':'Technology',\n",
    "                   'Address':'Street',\n",
    "                   'Town':'City',\n",
    "                   'Postal code':'Postcode',\n",
    "                   'Maximum, total, MW':'Capacity',\n",
    "                   'Main fuel':'Fuel',\n",
    "                   'Commissioned':'Commissioned',\n",
    "                   'Country':'Country',\n",
    "                   'Source':'Source'}\n",
    "data_FI.rename(columns=dict_columns_FI, inplace=True)\n",
    "\n",
    "# Check if all columns have been renamed\n",
    "for columnnames in data_FI.columns:\n",
    "    #print(columnnames)\n",
    "    if not columnnames in dict_columns_FI.values():\n",
    "        logger.error(\"Not renamed column: \"+ columnnames)\n",
    "    \n",
    "# Sort columns\n",
    "columns_sorted_FI = ['Company',\n",
    "                     'Name',\n",
    "                     'Street',\n",
    "                     'Postcode',\n",
    "                     'City',\n",
    "                     'Country',\n",
    "                     'Capacity',\n",
    "                     'Fuel',\n",
    "                     'Technology',\n",
    "                     'Type',\n",
    "                     'CHP',\n",
    "                     'Commissioned',\n",
    "                     'Comment',\n",
    "                     'Source',\n",
    "                     'EIC-Code',\n",
    "                     'Availability',\n",
    "                     'Lat',\n",
    "                     'Lon']\n",
    "data_FI = data_FI.reindex(columns=columns_sorted_FI)\n",
    "\n",
    "#Adjust types of entries in all columns\n",
    "data_FI.Company = data_FI.Company.astype(str)\n",
    "data_FI.Name = data_FI.Name.astype(str)\n",
    "data_FI.Street = data_FI.Street.astype(str)\n",
    "data_FI.Postcode = data_FI.Postcode.astype(str)\n",
    "data_FI.City = data_FI.City.astype(str)\n",
    "data_FI.Country = data_FI.Country.astype(str)\n",
    "data_FI.Capacity = data_FI.Capacity.astype(float)\n",
    "data_FI.Fuel = data_FI.Fuel.astype(str)\n",
    "data_FI.Technology = data_FI.Technology.astype(str)\n",
    "data_FI.Type = data_FI.Type.astype(str)\n",
    "data_FI.CHP = data_FI.CHP.astype(str)\n",
    "data_FI.Commissioned = data_FI.Commissioned.astype(str)\n",
    "data_FI.Comment = data_FI.Comment.astype(str)\n",
    "data_FI.Source = data_FI.Source.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Fuel types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all fuel types mentioned in the column \"Fuel\" and subsequent translation check. Generation of entries for the column \"Fuel\" according to information given in the column \"Type\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename fuel types\n",
    "dict_fuels_FI = {'Biogas':'biogas',\n",
    "                 'Black liquor and concentrated liquors': 'UNKNOWN',\n",
    "                 'Blast furnace gas':'gas',\n",
    "                 'By-products from wood processing industry':'biomass',\n",
    "                 'Exothermic heat from industry':'UNKNOWN',\n",
    "                 'Forest fuelwood':'biomass',\n",
    "                 'Gasified waste':'waste',\n",
    "                 'Hard coal and anthracite':'coal',\n",
    "                 'Heavy distillates':'oil',\n",
    "                 'Industrial wood residues':'biomass',\n",
    "                 'Light distillates':'oil',\n",
    "                 'Medium heavy distillates':'oil',\n",
    "                 'Mixed fuels':'multiple_non_renewable',\n",
    "                 'Natural gas':'gas',\n",
    "                 'Nuclear energy':'uranium',\n",
    "                 'Other by-products and wastes used as fuel':'UNKNOWN',\n",
    "                 'Other non-specified energy sources':'UNKNOWN',\n",
    "                 'Peat':'biomass',\n",
    "                 ' ':'UNKNOWN'}\n",
    "data_FI[\"Fuel\"].replace(dict_fuels_FI, inplace=True)\n",
    "data_FI[\"Fuel\"].unique()\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for fuel in data_FI[\"Fuel\"].unique():\n",
    "    if (not fuel in dict_fuels_FI.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Not renamed fuel type: \" + str(fuel)) \n",
    "\n",
    "# Generate entries in column \"fuel\" for hydro and wind stations according to column \"type\"\n",
    "data_FI['Fuel'][data_FI['Type'] == 'Hydro power'] = 'hydro'\n",
    "data_FI['Fuel'][data_FI['Type'] == 'Wind power'] = 'wind'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Technology types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of entries for the column \"Technology\" according to information given in the column \"Fuel\". Deletion of rows containing \"wind\" as fuel type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate entries in column \"technology\" according to column \"fuel\"\n",
    "data_FI['Technology'][data_FI['Fuel'] == 'hydro'] = 'hydro_plant'\n",
    "data_FI['Technology'][data_FI['Fuel'] == 'uranium'] = 'ST'\n",
    "data_FI['Technology'][data_FI['Fuel'] == 'wind'] = 'wind_turbine'\n",
    "\n",
    "# Delete unwanted fuel (wind) in column \"fuel\"\n",
    "data_FI = data_FI[data_FI.Fuel != 'wind']\n",
    "\n",
    "# Rename technologies\n",
    "dict_technologies_FI = {' ':'UNKNOWN'}\n",
    "data_FI[\"Technology\"].replace(dict_technologies_FI, inplace=True)\n",
    "data_FI[\"Technology\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all types mentioned in the column \"Type\" and subsequent translation check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename types\n",
    "dict_types_FI = {'District heating CHP':'CHP',\n",
    "                 'Hydro power': '',\n",
    "                 'Industry CHP':'IPP',\n",
    "                 'Nuclear energy':'',\n",
    "                 'Separate electricity production':'',\n",
    "                 'Wind power':''}\n",
    "data_FI[\"Type\"].replace(dict_types_FI, inplace=True)\n",
    "data_FI[\"Type\"].unique()\n",
    "\n",
    "# Check if all types have been translated\n",
    "for fuel in data_FI[\"Type\"].unique():\n",
    "    if (not fuel in dict_types_FI.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Not renamed type: \" + str(fuel)) \n",
    "\n",
    "data_FI.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if input works\n",
    "data_PL = importdata('PL','GPI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall adjustment of all columns within the dataframe. Translation, completion, addition, deletion, sorting of columns as well as adjustment of the column entries' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename first column\n",
    "data_PL.columns.values[0] = 'Company'\n",
    "\n",
    "# Add columns with empty data\n",
    "data_PL['Street'] = 'NaN'\n",
    "data_PL['Postcode'] = 'NaN'\n",
    "data_PL['City'] = 'NaN'\n",
    "data_PL['Technology'] = 'UNKNOWN'\n",
    "data_PL['Type'] = 'NaN'\n",
    "data_PL['CHP'] = 'NaN'\n",
    "data_PL['Commissioned'] = 'NaN'\n",
    "\n",
    "# Rename columns\n",
    "dict_columns_PL = {'Company':'Company',\n",
    "                   'Generating unit name':'Name',\n",
    "                   'Street':'Street',\n",
    "                   'Postcode':'Postcode',\n",
    "                   'City':'City',\n",
    "                   'Technology':'Technology',\n",
    "                   'Type':'Type',\n",
    "                   'CHP':'CHP',\n",
    "                   'Comments':'Comment',\n",
    "                   'Commissioned':'Commissioned',\n",
    "                   'Available capacity [MW]':'Capacity',\n",
    "                   'Basic fuel':'Fuel',\n",
    "                   'Country':'Country',\n",
    "                   'Source':'Source'}\n",
    "data_PL.rename(columns=dict_columns_PL, inplace=True)\n",
    "\n",
    "# Check if all columns have been renamed\n",
    "for columnnames in data_PL.columns:\n",
    "    #print(columnnames)\n",
    "    if not columnnames in dict_columns_PL.values():\n",
    "        logger.error(\"Not renamed column: \"+ columnnames)\n",
    "\n",
    "# Fill columns \"fuel\" and \"company\" with the respective entries\n",
    "cols = ['Fuel', 'Company']\n",
    "data_PL[cols] = data_PL[cols].ffill()\n",
    "\n",
    "# Delete empty and therefore unwanted rows by referring to column \"Generating unit code\"\n",
    "data_PL = data_PL.dropna(subset=['Generating unit code'])\n",
    "\n",
    "# Drop columns not needed anymore\n",
    "colsToDrop = ['Generating unit code','Voltage [kv]']\n",
    "data_PL = data_PL.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Sort columns\n",
    "columns_sorted_PL = ['Company',\n",
    "                     'Name',\n",
    "                     'Street',\n",
    "                     'Postcode',\n",
    "                     'City',\n",
    "                     'Country',\n",
    "                     'Capacity',\n",
    "                     'Fuel',\n",
    "                     'Technology',\n",
    "                     'Type',\n",
    "                     'CHP',\n",
    "                     'Commissioned',\n",
    "                     'Comment',\n",
    "                     'Source',\n",
    "                     'EIC-Code',\n",
    "                     'Availability',\n",
    "                     'Lat',\n",
    "                     'Lon']\n",
    "data_PL = data_PL.reindex(columns=columns_sorted_PL)\n",
    "\n",
    "#Adjust types of entries in all columns\n",
    "data_PL.Company = data_PL.Company.astype(str)\n",
    "data_PL.Name = data_PL.Name.astype(str)\n",
    "data_PL.Street = data_PL.Street.astype(str)\n",
    "data_PL.Postcode = data_PL.Postcode.astype(str)\n",
    "data_PL.City = data_PL.City.astype(str)\n",
    "data_PL.Country = data_PL.Country.astype(str)\n",
    "data_PL.Capacity = data_PL.Capacity.astype(float)\n",
    "data_PL.Fuel = data_PL.Fuel.astype(str)\n",
    "data_PL.Technology = data_PL.Technology.astype(str)\n",
    "data_PL.Type = data_PL.Type.astype(str)\n",
    "data_PL.CHP = data_PL.CHP.astype(str)\n",
    "data_PL.Commissioned = data_PL.Commissioned.astype(str)\n",
    "data_PL.Comment = data_PL.Comment.astype(str)\n",
    "data_PL.Source = data_PL.Source.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Fuel types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all fuel types mentioned in the column \"Fuel\" and subsequent translation check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename fuel types\n",
    "dict_fuels_PL = {'Brown coal':'lignite',\n",
    "                 'Black coal':'coal',\n",
    "                 'Water':'hydro'}\n",
    "data_PL[\"Fuel\"].replace(dict_fuels_PL, inplace=True)\n",
    "data_PL[\"Fuel\"].unique()\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for fuel in data_PL[\"Fuel\"].unique():\n",
    "    if (not fuel in dict_fuels_PL.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Not renamed fuel type: \" + str(fuel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Technology types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of entries for the column \"Technology\" according to information given in the column \"Fuel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate entries in column \"technology\" according to fuel \"hydro\"\n",
    "data_PL['Technology'][data_PL['Fuel'] == 'hydro'] = 'PSP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merger of the multiple Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Access the second list\n",
    "data_PL2_filepath = 'data_processed/Further_Lists/data_PL_2.xlsx'\n",
    "data_PL2 = pd.read_excel(data_PL2_filepath, sheetname= 'pp_list_PL2')\n",
    "\n",
    "# Merge the lists\n",
    "data_PL = data_PL.append(data_PL2)\n",
    "\n",
    "data_PL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if input works\n",
    "data_ES = importdata('ES','SEDE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Decision, which of both columns \"Net_Capacity\" and \"Capacity\" will be dropped, has to be taken.\n",
    "\n",
    "Overall adjustment of all columns within the dataframe. Translation, addition, deletion, sorting of columns as well as adjustment of the column entries' types. Adjustment of the entries' units from kW to MW in the columns \"Net_Capacity\" and \"Capacity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Delete unwanted regions\n",
    "data_ES = data_ES[data_ES.Autonomia != 'Ceuta']\n",
    "data_ES = data_ES[data_ES.Autonomia != 'Melilla']\n",
    "data_ES = data_ES[data_ES.Autonomia != 'Canarias']\n",
    "data_ES = data_ES[data_ES.Autonomia != 'Baleares']\n",
    "\n",
    "# Delete unwanted fuels\n",
    "data_ES = data_ES[data_ES.Tecnologia != 'Eolica terrestre']\n",
    "data_ES = data_ES[data_ES.Tecnologia != 'Fotovoltaica']\n",
    "\n",
    "# Drop columns not needed anymore\n",
    "colsToDrop = ['N. Orden',\n",
    "              'Tipo Regimen',\n",
    "              'Autonomia',\n",
    "              'Provincia',\n",
    "              'F. Alta',\n",
    "              'F. Baja',\n",
    "              'F. Alta Provicional',\n",
    "              'Alta Registro']\n",
    "data_ES = data_ES.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Add columns with empty data\n",
    "data_ES['Street'] = 'NaN'\n",
    "data_ES['Postcode'] = 'NaN'\n",
    "data_ES['Type'] = 'NaN'\n",
    "data_ES['CHP'] = 'NaN'\n",
    "\n",
    "# Rename columns\n",
    "dict_columns_ES = {'Titular':'Company',\n",
    "                   'Nombre de la instalacion':'Name',\n",
    "                   'Street':'Street',\n",
    "                   'Postcode':'Postcode',\n",
    "                   'Municipio':'City',\n",
    "                   'Tecnologia':'Technology',\n",
    "                   'Type':'Type',\n",
    "                   'CHP':'CHP',\n",
    "                   'Comment':'Comment',\n",
    "                   'Potencia Neta':'Net_Capacity',\n",
    "                   'Potencia Bruta':'Capacity',\n",
    "                   'Combustible':'Fuel',\n",
    "                   'F. Puesta En Servicio':'Commissioned',\n",
    "                   'Country':'Country',\n",
    "                   'Source':'Source'}\n",
    "data_ES.rename(columns=dict_columns_ES, inplace=True)\n",
    "\n",
    "# Check if all columns have been renamed\n",
    "for columnnames in data_ES.columns:\n",
    "    #print(columnnames)\n",
    "    if not columnnames in dict_columns_ES.values():\n",
    "        logger.error(\"Not renamed column: \"+ columnnames)\n",
    "        \n",
    "# Sort columns\n",
    "columns_sorted_ES = ['Company',\n",
    "                     'Name',\n",
    "                     'Street',\n",
    "                     'Postcode',\n",
    "                     'City',\n",
    "                     'Country',\n",
    "                     'Net_Capacity',\n",
    "                     'Capacity',\n",
    "                     'Fuel',\n",
    "                     'Technology',\n",
    "                     'Type',\n",
    "                     'CHP',\n",
    "                     'Commissioned',\n",
    "                     'Comment',\n",
    "                     'Source',\n",
    "                     'EIC-Code',\n",
    "                     'Availability',\n",
    "                     'Lat',\n",
    "                     'Lon']\n",
    "data_ES = data_ES.reindex(columns=columns_sorted_ES)\n",
    "\n",
    "\n",
    "# Change unit of column 'net_capacity' from kW to MW\n",
    "data_ES.Net_Capacity = data_ES.Net_Capacity.astype(float)\n",
    "data_ES['Net_Capacity'] = (data_ES['Net_Capacity']/1000)\n",
    "\n",
    "# Change unit of column 'capacity' from kW to MW\n",
    "data_ES.Capacity = data_ES.Capacity.astype(float)\n",
    "data_ES['Capacity'] = (data_ES['Capacity']/1000)\n",
    "\n",
    "# Define commissioning year\n",
    "data_ES['Commissioned'] = pd.to_datetime(data_ES['Commissioned'], format='%d/%m/%Y')\n",
    "data_ES['Commissioned'] = pd.DatetimeIndex(data_ES['Commissioned']).year\n",
    "\n",
    "#Adjust types of entries in all columns\n",
    "data_ES.Company = data_ES.Company.astype(str)\n",
    "data_ES.Name = data_ES.Name.astype(str)\n",
    "data_ES.Street = data_ES.Street.astype(str)\n",
    "data_ES.Postcode = data_ES.Postcode.astype(str)\n",
    "data_ES.City = data_ES.City.astype(str)\n",
    "data_ES.Country = data_ES.Country.astype(str)\n",
    "data_ES.Fuel = data_ES.Fuel.astype(str)\n",
    "data_ES.Technology = data_ES.Technology.astype(str)\n",
    "data_ES.Type = data_ES.Type.astype(str)\n",
    "data_ES.CHP = data_ES.CHP.astype(str)\n",
    "data_ES.Commissioned = data_ES.Commissioned.astype(str)\n",
    "data_ES.Comment = data_ES.Comment.astype(str)\n",
    "data_ES.Source = data_ES.Source.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Fuel types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all fuel types mentioned in the column \"Fuel\" and subsequent translation check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_fuels_ES = {'Biocombustibles liquidos':'biomass',\n",
    "                 'Biogas': 'biogas',\n",
    "                 'Biogas de digestion':'biogas',\n",
    "                 'Biogas de vertedero':'biogas',\n",
    "                 'Biomasa industrial agricola':'biomass',\n",
    "                 'Biomasa industrial forestal':'biomass',\n",
    "                 'Biomasa primaria':'biomass',\n",
    "                 'Calor residual':'UNKNOWN',\n",
    "                 'Carbon':'coal',\n",
    "                 'CARBON IMPORTADO':'coal',\n",
    "                 'Cultivos energeticos agricolas o forestales':'biomass',\n",
    "                 'DIESEL':'oil',\n",
    "                 'Energias residuales':'UNKNOWN',\n",
    "                 'Fuel':'oil',\n",
    "                 'FUEL-OIL 0,3':'oil',\n",
    "                 'FUELOLEO':'oil',\n",
    "                 'GAS DE REFINERIA':'gas',                 \n",
    "                 'Gas natural':'gas',\n",
    "                 'GAS NATURAL':'gas',\n",
    "                 'Gas residual':'gas',\n",
    "                 'Gasoleo':'gas',\n",
    "                 'GASOLEO':'gas',\n",
    "                 'HULLA+ANTRACITA':'coal',\n",
    "                 'Licores negros':'biomass',\n",
    "                 'LIGNITO NEGRO':'lignite',\n",
    "                 'LIGNITO PARDO':'lignite',\n",
    "                 'NUCLEAR':'uranium',\n",
    "                 'Propano':'gas',\n",
    "                 'Residuo aprovechamiento forestal o selvicola':'waste',\n",
    "                 'Residuos':'waste',\n",
    "                 'Residuos actividad agricolas o jardineria':'waste',\n",
    "                 'Residuos industriales':'waste',\n",
    "                 'Residuos solidos urbanos':'waste',\n",
    "                 'RESIDUOS SOLIDOS URBANOS':'waste',\n",
    "                ' ':'UNKNOWN'}\n",
    "data_ES[\"Fuel\"].replace(dict_fuels_ES, inplace=True)\n",
    "data_ES[\"Fuel\"].unique()\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for fuel in data_ES[\"Fuel\"].unique():\n",
    "    if (not fuel in dict_fuels_ES.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Not renamed fuel type: \" + str(fuel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Technology types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- Open question on meaning of technology \"cogeneratcion\" (CCGT or CHP?)\n",
    "- Exlcude power plants at Baleares, Canarias, Melilla, and Ceuta\n",
    "\n",
    "Overall translation of all technology types mentioned in the column \"Technology\" and subsequent translation check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_technologies_ES = {'Cogeneracion':'CC',\n",
    "                        'Eolica terrestre': 'wind_turbine',\n",
    "                        'Hidraulica fluyente':'ROR',\n",
    "                        'Hidraulica':'hydro_plant',\n",
    "                        'Termonuclear':'ST',\n",
    "                        'Turbina de gas':'GT',\n",
    "                        ' ':'UNKNOWN'}\n",
    "data_ES[\"Technology\"].replace(dict_technologies_ES, inplace=True)\n",
    "data_ES[\"Technology\"].unique()\n",
    "\n",
    "# Check if all technologies have been translated\n",
    "for fuel in data_ES[\"Technology\"].unique():\n",
    "    if (not fuel in dict_technologies_ES.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Untranslated technology: \" + str(fuel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and adjust Fuel types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of entries for the column \"Fuel\" according to information given in the column \"Technology\". Deletion of rows containing \"wind\" and \"solar\" as fuel type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate entries in column \"fuel\" for hydro, wind and solar stations according to column \"technology\"\n",
    "data_ES['Fuel'][data_ES['Technology'] == 'hydro_plant'] = 'hydro'\n",
    "data_ES['Fuel'][data_ES['Technology'] == 'ROR'] = 'hydro'\n",
    "\n",
    "# Generate entries in column \"CHP\" according to column \"Technology\"\n",
    "#data_ES['CHP'][data_ES['Technology'] == 'CC'] = 'Yes'\n",
    "\n",
    "# Generate entries in column \"Type\" according to column \"Technology\"\n",
    "#data_ES['Type'][data_ES['Technology'] == 'CC'] = 'CHP'\n",
    "\n",
    "data_ES.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if input works\n",
    "data_UK = importdata('UK','GOV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall adjustment of all columns within the dataframe. Translation, addition, deletion, sorting of columns as well as adjustment of the column entries' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rename sixth column\n",
    "data_UK.columns.values[5] = 'Location'\n",
    "\n",
    "# Drop rows without station names, so that the footnotes at the end of the list are deleted\n",
    "data_UK = data_UK.dropna(subset=['Station Name'])\n",
    "\n",
    "# Drop columns not needed anymore\n",
    "colsToDrop = ['Footnotes']\n",
    "data_UK = data_UK.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Add needed columns without data\n",
    "data_UK['Street'] = 'NaN'\n",
    "data_UK['Postcode'] = 'NaN'\n",
    "data_UK['City'] = 'NaN'\n",
    "data_UK['Technology'] = 'UNKNOWN'\n",
    "data_UK['CHP'] = 'NaN'\n",
    "data_UK['Type'] = 'NaN'\n",
    "data_UK['Comment'] = 'NaN'\n",
    "\n",
    "# Rename columns\n",
    "dict_columns_UK = {'Company Name':'Company',\n",
    "                   'Station Name':'Name',\n",
    "                   'Installed Capacity (MW)':'Capacity',\n",
    "                   'Street':'Street',\n",
    "                   'Postcode':'Postcode',\n",
    "                   'City':'City',\n",
    "                   'Country':'Country',\n",
    "                   'Location':'Location',\n",
    "                   'Fuel':'Fuel',\n",
    "                   'Technology':'Technology',\n",
    "                   'Type':'Type',\n",
    "                   'CHP':'CHP',\n",
    "                   'Year of commission or year generation began':'Commissioned',\n",
    "                   'Comment':'Comment',\n",
    "                   'Source':'Source'}\n",
    "data_UK.rename(columns=dict_columns_UK, inplace=True)\n",
    "\n",
    "# Check if all columns have been renamed\n",
    "for columnnames in data_UK.columns:\n",
    "    #print(columnnames)\n",
    "    if not columnnames in dict_columns_UK.values():\n",
    "        logger.error(\"Not renamed column: \"+ columnnames)\n",
    "\n",
    "# Sort columns\n",
    "columns_sorted_UK = ['Company',\n",
    "                     'Name',\n",
    "                     'Street',\n",
    "                     'Postcode',\n",
    "                     'City',\n",
    "                     'Country',\n",
    "                     'Location',\n",
    "                     'Capacity',\n",
    "                     'Fuel',\n",
    "                     'Technology',\n",
    "                     'Type',\n",
    "                     'CHP',\n",
    "                     'Commissioned',\n",
    "                     'Comment',\n",
    "                     'Source',\n",
    "                     'EIC-Code',\n",
    "                     'Availability',\n",
    "                     'Lat',\n",
    "                     'Lon']\n",
    "data_UK = data_UK.reindex(columns=columns_sorted_UK)\n",
    "\n",
    "# Adjust names of region\n",
    "dict_regions_UK = {'East':'England',\n",
    "                 'East Midlands':'England',\n",
    "                 'London':'England',\n",
    "                 'North East':'England',\n",
    "                 'North West':'England',\n",
    "                 'South East':'England',\n",
    "                 'South West':'England',\n",
    "                 'West Midlands':'England',\n",
    "                 'Yorkshire and the Humber':'England',\n",
    "                 'N Ireland':'Northern Ireland'}\n",
    "data_UK[\"Location\"].replace(dict_regions_UK, inplace=True)\n",
    "data_UK[\"Location\"].unique()\n",
    "\n",
    "# Merge columns \"Country\" and \"Location\" to one column called \"Country\"\n",
    "data_UK['Country'] = data_UK[['Country','Location']].apply(lambda x : '{} - {}'.format(x[0],x[1]), axis=1)\n",
    "\n",
    "# Drop column \"Location\" after merger\n",
    "colsToDrop = ['Location']\n",
    "data_UK = data_UK.drop(colsToDrop, axis=1)\n",
    "\n",
    "#Adjust types of entries in all columns\n",
    "data_UK.Company = data_UK.Company.astype(str)\n",
    "data_UK.Name = data_UK.Name.astype(str)\n",
    "data_UK.Street = data_UK.Street.astype(str)\n",
    "data_UK.Postcode = data_UK.Postcode.astype(str)\n",
    "data_UK.City = data_UK.City.astype(str)\n",
    "data_UK.Country = data_UK.Country.astype(str)\n",
    "data_UK.Capacity = data_UK.Capacity.astype(float)\n",
    "data_UK.Fuel = data_UK.Fuel.astype(str)\n",
    "data_UK.Technology = data_UK.Technology.astype(str)\n",
    "data_UK.Type = data_UK.Type.astype(str)\n",
    "data_UK.CHP = data_UK.CHP.astype(str)\n",
    "data_UK.Commissioned = data_UK.Commissioned.astype(str)\n",
    "data_UK.Comment = data_UK.Comment.astype(str)\n",
    "data_UK.Source = data_UK.Source.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and adjust Technology types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of entries for the column \"Technology\" according to information given in the column \"Fuel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate entries in column \"technology\" according to hydro fuels\n",
    "data_UK['Technology'][data_UK['Fuel'] == 'Hydro'] = 'hydro_plant'\n",
    "data_UK['Technology'][data_UK['Fuel'] == 'Hydro / pumped storage'] = 'PSP'\n",
    "data_UK['Technology'][data_UK['Fuel'] == 'Pumped storage'] = 'PSP'\n",
    "data_UK['Technology'][data_UK['Fuel'] == 'Wind'] = 'wind_turbine'\n",
    "data_UK['Technology'][data_UK['Fuel'] == 'Wind (offshore)'] = 'wind_turbine'\n",
    "data_UK['Technology'][data_UK['Fuel'] == 'Nuclear'] = 'ST'\n",
    "data_UK['Technology'][data_UK['Fuel'] == 'CCGT'] = 'CC'\n",
    "data_UK['Technology'][data_UK['Fuel'] == 'OCGT'] = 'GT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Fuel types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all fuel types mentioned in the column \"Fuel\" and subsequent translation check. Deletion of rows containing \"wind\" as fuel type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_fuels_UK = {'Biomass':'biomass',\n",
    "                 'CCGT': 'gas',\n",
    "                 'Coal':'coal',\n",
    "                 'Coal / biomass':'coal',\n",
    "                 'Coal / biomass / gas / waste derived fuel':'coal',\n",
    "                 'Coal / oil':'coal',\n",
    "                 'Diesel':'oil',\n",
    "                 'Gas':'gas',\n",
    "                 'Gas / oil':'gas',\n",
    "                 'Gas oil':'oil',\n",
    "                 'Gas oil / kerosene':'oil',\n",
    "                 'Hydro':'hydro',\n",
    "                 'Hydro / pumped storage':'hydro',\n",
    "                 'Light oil':'oil',\n",
    "                 'Meat & bone meal':'waste',\n",
    "                 'Nuclear':'uranium',\n",
    "                 'OCGT':'gas',                 \n",
    "                 'Oil':'oil',\n",
    "                 'Pumped storage':'hydro',\n",
    "                 'Straw':'biomass',\n",
    "                 'Waste':'waste',\n",
    "                 'Wind':'wind',\n",
    "                 'Wind (offshore)':'wind'}\n",
    "data_UK[\"Fuel\"].replace(dict_fuels_UK, inplace=True)\n",
    "data_UK[\"Fuel\"].unique()\n",
    "\n",
    "# Check if all fuels have been translated\n",
    "for fuel in data_UK[\"Fuel\"].unique():\n",
    "    if (not fuel in dict_fuels_UK.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Not renamed fuel type: \" + str(fuel))\n",
    "        \n",
    "# Delete unwanted fuels\n",
    "data_UK = data_UK[data_UK.Fuel != 'wind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Czech Republic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if input works\n",
    "data_CZ = importdata('CZ','CEPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall adjustment of all columns within the dataframe. Translation, addition, deletion, sorting of columns as well as adjustment of the column entries' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge columns \"Power plant\" and \"Generating unit\" to one column called \"Name\"\n",
    "data_CZ['Name'] = data_CZ[['Power plant','Generating unit']].apply(lambda x : '{} {}'.format(x[0],x[1]), axis=1)\n",
    "\n",
    "# Drop columns not needed anymore\n",
    "colsToDrop = ['Date','Power plant','Generating unit']\n",
    "data_CZ = data_CZ.drop(colsToDrop, axis=1)\n",
    "\n",
    "# Rename columns\n",
    "dict_columns_CZ = {'Name':'Name',\n",
    "                   'Available capacity [MW]':'Capacity',\n",
    "                   'Type of source':'Technology',\n",
    "                   'Country':'Country',\n",
    "                   'Source':'Source'}\n",
    "data_CZ.rename(columns=dict_columns_CZ, inplace=True)\n",
    "\n",
    "# Check if all columns have been renamed\n",
    "for columnnames in data_CZ.columns:\n",
    "    #print(columnnames)\n",
    "    if not columnnames in dict_columns_CZ.values():\n",
    "        logger.error(\"Not renamed column: \"+ columnnames)\n",
    "\n",
    "# Filter rows by considering \"name\" and maximum \"capacity\"\n",
    "data_CZ = data_CZ.sort_values('Capacity', ascending=False).groupby('Name', as_index=False).first()\n",
    "\n",
    "# Add needed columns with/without data\n",
    "data_CZ['Company'] = 'NaN'\n",
    "data_CZ['Street'] = 'NaN'\n",
    "data_CZ['Postcode'] = 'NaN'\n",
    "data_CZ['City'] = 'NaN'\n",
    "data_CZ['Fuel'] = 'UNKNOWN'\n",
    "data_CZ['CHP'] = 'NaN'\n",
    "data_CZ['Type'] = 'NaN'\n",
    "data_CZ['Comment'] = 'NaN'\n",
    "data_CZ['Commissioned'] = 'NaN'\n",
    "\n",
    "# Sort columns\n",
    "columns_sorted_CZ = ['Company',\n",
    "                     'Name',\n",
    "                     'Street',\n",
    "                     'Postcode',\n",
    "                     'City',\n",
    "                     'Country',\n",
    "                     'Capacity',\n",
    "                     'Fuel',\n",
    "                     'Technology',\n",
    "                     'Type',\n",
    "                     'CHP',\n",
    "                     'Commissioned',\n",
    "                     'Comment',\n",
    "                     'Source',\n",
    "                     'EIC-Code',\n",
    "                     'Availability',\n",
    "                     'Lat',\n",
    "                     'Lon']\n",
    "data_CZ = data_CZ.reindex(columns=columns_sorted_CZ)\n",
    "\n",
    "#Adjust types of entries in all columns\n",
    "data_CZ.Company = data_CZ.Company.astype(str)\n",
    "data_CZ.Name = data_CZ.Name.astype(str)\n",
    "data_CZ.Street = data_CZ.Street.astype(str)\n",
    "data_CZ.Postcode = data_CZ.Postcode.astype(str)\n",
    "data_CZ.City = data_CZ.City.astype(str)\n",
    "data_CZ.Country = data_CZ.Country.astype(str)\n",
    "data_CZ.Capacity = data_CZ.Capacity.astype(float)\n",
    "data_CZ.Fuel = data_CZ.Fuel.astype(str)\n",
    "data_CZ.Technology = data_CZ.Technology.astype(str)\n",
    "data_CZ.Type = data_CZ.Type.astype(str)\n",
    "data_CZ.CHP = data_CZ.CHP.astype(str)\n",
    "data_CZ.Commissioned = data_CZ.Commissioned.astype(str)\n",
    "data_CZ.Comment = data_CZ.Comment.astype(str)\n",
    "data_CZ.Source = data_CZ.Source.astype(str)\n",
    "\n",
    "data_CZ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate and adjust Technology types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall translation of all technology types mentioned in the column \"Technology\" and subsequent translation check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate entries in column \"fuel\" for hydro, wind and solar stations according to column \"technology\"\n",
    "data_CZ['Fuel'][data_CZ['Technology'] == 'Jaderná elektrárna'] = 'uranium'\n",
    "data_CZ['Fuel'][data_CZ['Technology'] == 'Přečerpávací vodní elektrárna'] = 'hydro'\n",
    "data_CZ['Fuel'][data_CZ['Technology'] == 'Parní elektrárna'] = 'NaN'\n",
    "data_CZ['Fuel'][data_CZ['Technology'] == 'Paroplynová elektrárna'] = 'gas'\n",
    "\n",
    "# translate technologies\n",
    "dict_technologies_CZ = {'Přečerpávací vodní elektrárna':'PSP',\n",
    "                        'Parní elektrárna': 'ST',\n",
    "                        'Jaderná elektrárna':'ST',\n",
    "                        'Paroplynová elektrárna':'CC'}\n",
    "data_CZ[\"Technology\"].replace(dict_technologies_CZ, inplace=True)\n",
    "data_CZ[\"Technology\"].unique()\n",
    "\n",
    "# Check if all technologies have been translated\n",
    "for fuel in data_CZ[\"Technology\"].unique():\n",
    "    if (not fuel in dict_technologies_CZ.values()) & (str(fuel) != \"nan\"):\n",
    "        logger.error(\"Untranslated technology: \" + str(fuel))\n",
    "        \n",
    "data_CZ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merger of the multiple Lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Access the second list\n",
    "data_CZ2_filepath = 'data_processed/Further_Lists/data_CZ_2.xlsx'\n",
    "data_CZ2 = pd.read_excel(data_CZ2_filepath, sheetname= 'pp_list_CZ2')\n",
    "\n",
    "# Merge the lists\n",
    "data_CZ = data_CZ.append(data_CZ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of hydropower data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import detailed technical hydro power data\n",
    "data_CH = importdata('CH','BFE_HydroData')\n",
    "data_CH = data_CH.set_index(['ZE-Nr'])\n",
    "#data_CH.head()\n",
    "\n",
    "# Import geographical data on swiss hydro power plants\n",
    "data_CHgeo = importdata('CH','BFE_HydroGeo')\n",
    "data_CHgeo = data_CHgeo.set_index(['WASTANumbe'])\n",
    "#data_CHgeo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation of geographical hydro power data to WGS84 projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wgs84=pyproj.Proj(\"+init=EPSG:4326\") # LatLon with WGS84 datum used by GPS units and Google Earth\n",
    "ch1903=pyproj.Proj(\"+init=EPSG:21781\") #CH1903 projection used in BFE-Data\n",
    "\n",
    "data_CHgeo[['lon','lat']] = data_CHgeo[['X','Y']].apply(lambda row: \n",
    "                                                        pyproj.transform(ch1903,wgs84,row[0],row[1]), axis=1).apply(pd.Series)\n",
    "data_CHgeo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge technical and geographical hydro power data to a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_CH = pd.merge(data_CH,data_CHgeo,left_index=True, right_index=True, how='left')\n",
    "data_CH = data_CH.reset_index()\n",
    "data_CH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create output-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_UK.to_csv('data_processed/data_UK.csv')\n",
    "data_CZ.to_csv('data_processed/data_CZ.csv')\n",
    "data_ES.to_csv('data_processed/data_ES.csv')\n",
    "data_PL.to_csv('data_processed/data_PL.csv')\n",
    "data_NL.to_csv('data_processed/data_NL.csv')\n",
    "data_FR.to_csv('data_processed/data_FR.csv')\n",
    "data_BE.to_csv('data_processed/data_BE.csv')\n",
    "data_FI.to_csv('data_processed/data_FI.csv')\n",
    "data_IT.to_csv('data_processed/data_IT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documenting the data package (meta data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We document the data packages meta data in the specific format JSON as proposed by the Open Knowledge Foundation. See the Frictionless Data project by OKFN (http://data.okfn.org/) and the Data Package specifications (http://dataprotocols.org/data-packages/) for more details.\n",
    "\n",
    "In order to keep the notebook more readable, we first formulate the metadata in the human-readable YAML format using a multi-line string. We then parse the string into a Python dictionary and save that to disk as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we define meta data of the resulting data package.\n",
    "# The meta data follows the specification at:\n",
    "# http://dataprotocols.org/data-packages/\n",
    "\n",
    "metadata = \"\"\"\n",
    "\n",
    "name: opsd-power-plants-europe\n",
    "title: Power plants of European countries\n",
    "description: xxx\n",
    "version: \"2016-04-22\"\n",
    "keywords: [power plants,europe]\n",
    "opsd-jupyter-notebook-url: \"https://github.com/Open-Power-System-Data/datapackage_power_plants_europe/blob/master/main.ipynb\"\n",
    "geographical-scope: Europe\n",
    "opsd-changes-to-last-version: xxx\n",
    "\n",
    "resources:\n",
    "    - path: xxx.csv\n",
    "      format: csv\n",
    "      mediatype: text/csv\n",
    "      schema:    \n",
    "        fields:\n",
    "            - name:\n",
    "              description:\n",
    "              type: \n",
    "    - path: xxx.xlsx\n",
    "      format: xlsx\n",
    "      mediatype: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n",
    "              \n",
    "licenses:\n",
    "    - url: http://example.com/license/url/here\n",
    "      name: License Name Here\n",
    "      version: 1.0\n",
    "      id: license-id-from-open\n",
    "\n",
    "sources:\n",
    "    - name: \n",
    "      web: \n",
    "maintainers:\n",
    "    - name: Friedrich Kunz\n",
    "      email: fkunz@diw.de\n",
    "      web: http://open-power-system-data.org/\n",
    "\n",
    "openpowersystemdata-enable-listing: True  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "metadata = yaml.load(metadata)\n",
    "\n",
    "datapackage_json = json.dumps(metadata, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = 'data_final/'\n",
    "\n",
    "#Write the result to file\n",
    "#data.to_csv(output_path+'power_plants_europe.csv', encoding='utf-8')\n",
    "\n",
    "#Write the results to excel file\n",
    "#data.to_excel(output_path+'power_plants_europe.xlsx', sheet_name='output')\n",
    "\n",
    "#Write the results to sql database\n",
    "#data.to_sql(output_path+'power_plants_europe', sqlite3.connect(output_path+'power_plants_europe.sqlite'), if_exists=\"replace\") \n",
    "\n",
    "#Write the information of the metadata\n",
    "with open(os.path.join(output_path, 'datapackage.json'), 'w') as f:\n",
    "    f.write(datapackage_json)\n",
    "\n",
    "#Set this string to this notebook's filename!    \n",
    "nb_filename = 'main.ipynb'\n",
    "\n",
    "# Save a copy of the notebook to markdown, to serve as the package README file\n",
    "subprocess.call(['ipython', 'nbconvert', '--to', 'markdown', nb_filename])\n",
    "path_readme = os.path.join(output_path, 'README.md')\n",
    "try:\n",
    "    os.remove(path_readme)\n",
    "except Exception:\n",
    "    pass\n",
    "os.rename(nb_filename.replace('.ipynb', '.md'), path_readme)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
